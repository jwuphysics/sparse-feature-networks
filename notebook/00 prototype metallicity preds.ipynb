{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e020f27-f9df-427b-ab22-b1d602920133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.basics import *\n",
    "from fastai.vision.all import *\n",
    "\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "ROOT = Path(\"..\").resolve()\n",
    "seed = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16c071b7-7ad1-4bc1-bbf8-fc898f3e3b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.font_manager as fm\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "fm.fontManager.addfont(\"/Users/john/Library/Fonts/Nunito-Regular.otf\")\n",
    "fm.fontManager.addfont(\"/Users/john/Library/Fonts/Nunito-Bold.otf\")\n",
    "fm.fontManager.addfont(\"/Users/john/Library/Fonts/Nunito-ExtraBold.otf\")\n",
    "\n",
    "plt.rcParams['font.family'] = 'Nunito'\n",
    "plt.rcParams['font.weight'] = \"bold\"\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=[\"#003f5c\",\"#7a5195\",\"#ef5675\",\"#ffa600\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a691254d-7d40-4cb1-bd9b-e046f58e6578",
   "metadata": {},
   "source": [
    "# Top-k resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdcc9afa-774f-4551-8738-6feeb82e4a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 4\n",
    "\n",
    "\n",
    "def RMSE(p, y): return torch.sqrt(MSELossFlat()(p, y))\n",
    "    \n",
    "class ResNetTopK(nn.Module):\n",
    "    \"\"\"Resnet18-like model with a single projection head at end, and a top-k \n",
    "    sparsity constraint in penultimate layer to encourage interpretability.\n",
    "    \"\"\"\n",
    "    def __init__(self, k=32, n_out=1000, pretrained=True, **kwargs):\n",
    "        super(ResNetTopK, self).__init__()\n",
    "        if pretrained:\n",
    "            self.resnet = resnet18(weights=ResNet18_Weights.DEFAULT, **kwargs)\n",
    "        else:\n",
    "            self.resnet = resnet18(weights=None, **kwargs)\n",
    "        self.k = k\n",
    "        # change n_out features\n",
    "        n_fc_in = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(n_fc_in, n_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Get features from all layers except the final FC\n",
    "        features = nn.Sequential(*list(self.resnet.children())[:-1])(x)\n",
    "        features = torch.flatten(features, 1)\n",
    "        \n",
    "        # Apply ReLU activation\n",
    "        features = nn.functional.relu(features)\n",
    "        \n",
    "        # top-k constraint\n",
    "        topk_values, topk_indices = torch.topk(features, k=self.k, dim=1)\n",
    "        sparse_features = torch.zeros_like(features)\n",
    "        sparse_features.scatter_(1, topk_indices, topk_values)\n",
    "\n",
    "        # print(f\"Non-zero activations per sample: {(sparse_features != 0).sum(1)}\")\n",
    "        \n",
    "        # final fully connected layer\n",
    "        x = self.resnet.fc(sparse_features)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ef1024b-4ee9-41c7-9a99-d69621c35726",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(ROOT / 'data/galaxies.csv', dtype={'objID': str})\n",
    "df = df[(df.oh_p50 > 0) & (df.lgm_tot_p50 > 0) & (df.sfr_tot_p50 > -10)].copy()\n",
    "\n",
    "# df = df.sample(10000, random_state=256).copy()\n",
    "\n",
    "n_galaxies = len(df)\n",
    "\n",
    "# set a random state\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d9bc544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20715758226595135"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.oh_p50.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "991d8f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117223"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c949590-abe0-47d1-9ac7-955383dc5ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fastai \"data blocks\" determine how data can be fed into a model\n",
    "dblock = DataBlock(\n",
    "    blocks=(ImageBlock, RegressionBlock),\n",
    "    get_x=ColReader('objID', pref=f'{ROOT}/data/images-sdss/', suff='.jpg'),\n",
    "    get_y=ColReader('oh_p50'),\n",
    "    splitter=RandomSplitter(0.2, seed=seed),\n",
    "    item_tfms=[Resize(160), CropPad(144)],\n",
    "    batch_tfms=aug_transforms(do_flip=True, flip_vert=True, max_rotate=0, max_zoom=1.0, max_warp=0, p_lighting=0) + [Normalize()]\n",
    ")\n",
    "\n",
    "# \"data loaders\" actually load the data \n",
    "dls = ImageDataLoaders.from_dblock(dblock, df, bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54b85256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29300"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls.train) * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5486d382-30d6-49c3-9009-975438bb9fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = ResNetTopK(k=K, n_out=1, pretrained=True).to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85a958b0-cd1d-4a2f-8bc8-9d79841dac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(\n",
    "    dls,\n",
    "    cnn_model,\n",
    "    loss_func=RMSE,\n",
    "    opt_func=ranger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bbb25f2-6e38-48c4-9729-f2c8cf2e2bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.318600</td>\n",
       "      <td>0.266086</td>\n",
       "      <td>11:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.186636</td>\n",
       "      <td>0.256424</td>\n",
       "      <td>12:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.218749</td>\n",
       "      <td>0.392514</td>\n",
       "      <td>18:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.181272</td>\n",
       "      <td>0.220448</td>\n",
       "      <td>12:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.181404</td>\n",
       "      <td>0.128711</td>\n",
       "      <td>12:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.180500</td>\n",
       "      <td>0.209401</td>\n",
       "      <td>12:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.170569</td>\n",
       "      <td>0.400013</td>\n",
       "      <td>12:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.124144</td>\n",
       "      <td>0.294467</td>\n",
       "      <td>12:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.112030</td>\n",
       "      <td>0.146191</td>\n",
       "      <td>12:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.101036</td>\n",
       "      <td>0.141136</td>\n",
       "      <td>12:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.099893</td>\n",
       "      <td>0.114392</td>\n",
       "      <td>12:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.098808</td>\n",
       "      <td>0.092235</td>\n",
       "      <td>12:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.094858</td>\n",
       "      <td>0.099468</td>\n",
       "      <td>45:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.094029</td>\n",
       "      <td>0.109264</td>\n",
       "      <td>21:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.090147</td>\n",
       "      <td>0.098562</td>\n",
       "      <td>11:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.089315</td>\n",
       "      <td>0.093778</td>\n",
       "      <td>11:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.089433</td>\n",
       "      <td>0.088044</td>\n",
       "      <td>12:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.088809</td>\n",
       "      <td>0.086372</td>\n",
       "      <td>12:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.087462</td>\n",
       "      <td>0.085872</td>\n",
       "      <td>12:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.086698</td>\n",
       "      <td>0.085516</td>\n",
       "      <td>12:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(20, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4ab6b80-899d-4374-a9f9-50d63b821cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hz/8kslz26x4w72kd6r6lm3zc480000gn/T/ipykernel_92357/928007578.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cnn_model = torch.load(model_path)\n"
     ]
    }
   ],
   "source": [
    "model_path = f\"{ROOT}/model/resnet18-topk_{K}-metallicity.pth\"\n",
    "# torch.save(learn.model, model_path)\n",
    "\n",
    "cnn_model = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379c94e0-6f15-4c48-b6f0-ccce8e4a8546",
   "metadata": {},
   "source": [
    "# View activated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fdb88dd-ed0c-4755-81d1-f69b631899c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_sparse_activations(loader, model):\n",
    "    activations = []\n",
    "    with torch.no_grad():\n",
    "        layers = nn.Sequential(*list(model.resnet.children())[:-1], nn.Flatten())\n",
    "        \n",
    "        for xb, _ in tqdm(loader):    \n",
    "            activations.append(layers(xb))\n",
    "    return torch.concat(activations, 0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a0bdef0-b58d-46ef-af83-ef446d0b464e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 367/367 [00:34<00:00, 10.75it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23444, 512)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activs = get_all_sparse_activations(dls.valid, cnn_model)\n",
    "activs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "609732da-cec5-4c5a-96d0-9df284852bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "activs_path = f\"{ROOT}/results/resnet18-topk_{K}-metallicity/activations.npy\"\n",
    "# np.save(activs_path, activs)\n",
    "\n",
    "activations = np.load(activs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d991a71c-e9e9-4dd7-bb04-fd55be7d3b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(activations.max(0) > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cc94148-1f37-4048-96f3-14e6aa54ad31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make a dictionary for every non-zero activated feature, where the\n",
    "# key is the latent activation index, and the value is a list of tuples\n",
    "# of (image index, activation strength)\n",
    "feature_dict = defaultdict(list)\n",
    "\n",
    "# Process each image's activations\n",
    "for img_idx, img_activations in enumerate(activations):\n",
    "    # Find non-zero activations\n",
    "    non_zero = np.nonzero(img_activations)[0]\n",
    "\n",
    "    # Add to dictionary\n",
    "    for feature_idx in non_zero:\n",
    "        activation_strength = img_activations[feature_idx]\n",
    "        feature_dict[int(feature_idx)].append((int(img_idx), float(activation_strength)))\n",
    "\n",
    "# Sort each list by activation strength in descending order\n",
    "for feature_idx in feature_dict:\n",
    "    feature_dict[feature_idx].sort(key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63fe939f-8a5a-4ea2-b336-b1dd2c9504b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(61, 23348), (256, 20605), (49, 9414), (461, 2784), (223, 48), (87, 40), (84, 1), (44, 10), (247, 1), (94, 2), (428, 1)]\n"
     ]
    }
   ],
   "source": [
    "print([(k, len(feature_dict[k])) for k in feature_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d1e5267-b3e9-4041-95bf-2bc7bf17382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_idx_to_objid = lambda idx: dls.valid.items.iloc[idx].objID\n",
    "\n",
    "def plot_max_activating_galaxies(feature_dict, activation_index, top_n=5):\n",
    "    galaxy_indices_and_activations = feature_dict[activation_index]\n",
    "\n",
    "    top_n = min(top_n, len(galaxy_indices_and_activations))\n",
    "\n",
    "    fig, axes = plt.subplots(1, top_n, figsize=(top_n * 1.5, 2), dpi=100, squeeze=0)\n",
    "    axes = axes.reshape(-1)\n",
    "    for ax, [galaxy_index, feature_activation] in zip(axes, galaxy_indices_and_activations):\n",
    "        image = Image.open(f\"{ROOT}/data/images-sdss/{valid_idx_to_objid(galaxy_index)}.jpg\")\n",
    "        ax.imshow(image, origin='lower')\n",
    "        # ax.set_title(f\"{feature_activation:.4f}\", fontsize=10)\n",
    "        ax.axis(\"off\")\n",
    "    fig.suptitle(f\"Z {activation_index}\", fontsize=12)\n",
    "    fig.subplots_adjust(left=0, right=1, top=0.8, wspace=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be421e25-d089-44b0-b976-2efc761abcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 15.30it/s]\n"
     ]
    }
   ],
   "source": [
    "for k in tqdm(feature_dict):\n",
    "    plot_max_activating_galaxies(feature_dict, k, top_n=9)\n",
    "    plt.savefig(f\"{ROOT}/results/resnet18-topk_{K}-metallicity/figures/{k}-examples.pdf\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b19a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for activation_index in tqdm(feature_dict):\n",
    "    if len(feature_dict[activation_index]) < 1000:\n",
    "        continue\n",
    "    galaxy_indices_and_activations = feature_dict[activation_index]\n",
    "\n",
    "    # top_n = min(top_n, len(galaxy_indices_and_activations))\n",
    "\n",
    "    fig, axes = plt.subplots(4, 8, figsize=(8 * 1.9, 4*2), dpi=100, squeeze=0)\n",
    "    axes = axes.reshape(-1)\n",
    "    for ax, [galaxy_index, feature_activation] in zip(axes, galaxy_indices_and_activations):\n",
    "        image = Image.open(f\"{ROOT}/data/images-sdss/{valid_idx_to_objid(galaxy_index)}.jpg\")\n",
    "        ax.imshow(image, origin='lower')\n",
    "        # ax.set_title(f\"{feature_activation:.4f}\", fontsize=10)\n",
    "        ax.axis(\"off\")\n",
    "    fig.suptitle(f\"Z {activation_index}\", fontsize=12)\n",
    "    fig.subplots_adjust(left=0, right=1, top=0.8, wspace=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168eccee-f810-4a2b-99cc-367427b57817",
   "metadata": {},
   "source": [
    "# Plot normalized activation vs metallicity\n",
    "\n",
    "Only use common activations (i.e. ones that have non-zero values for 100+ cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d896b810-7e95-490e-93fd-4fb9446651d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation  61 (N=23348): Pearson rho = 0.8513\n",
      "Activation 256 (N=20605): Pearson rho = -0.7182\n",
      "Activation  49 (N= 9414): Pearson rho = 0.5085\n",
      "Activation 461 (N= 2784): Pearson rho = 0.2808\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(3.5, 3.5), dpi=300)\n",
    "plt.rcParams['font.weight'] = 700\n",
    "\n",
    "i = 0\n",
    "\n",
    "for k in feature_dict:\n",
    "    # most common features\n",
    "    if len(feature_dict[k]) > 100:\n",
    "        Pearson_rho = np.corrcoef(activations[:, k] / activations[:, k].max(), dls.valid.items.oh_p50)[0,1]\n",
    "        \n",
    "        plt.scatter(\n",
    "            activations[:, k] / activations[:, k].max(),\n",
    "            dls.valid.items.oh_p50, \n",
    "            edgecolors=\"none\",\n",
    "            s=1,\n",
    "            rasterized=True,\n",
    "            # label=f\"#{k} ({len(feature_dict[k])})\",\n",
    "        )\n",
    "\n",
    "        plt.text(0.55, 0.35 + i*0.07, f\"Activation {k:>3}\", ha=\"left\", va=\"center\", fontsize=12, transform=plt.gca().transAxes, color=f\"C{i}\", fontfamily='Nunito', fontweight='extra bold')\n",
    "\n",
    "        print(f\"Activation {k:>3} (N={len(feature_dict[k]):>5}): Pearson rho = {Pearson_rho:.4f}\")\n",
    "        i += 1\n",
    "plt.xlabel(\"Normalized activation strength\", fontsize=12, fontweight=\"bold\")\n",
    "plt.ylabel(\"12 + log(O/H)\", fontsize=12, fontweight=\"bold\")\n",
    "# plt.legend(markerscale=10, loc=\"center right\", framealpha=0, markerfirst=False, borderpad=0.05, handletextpad=0.05, title_fontsize=14)\n",
    "plt.grid(alpha=0.15)\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(8, 9.3)\n",
    "plt.savefig(f\"{ROOT}/results/resnet18-topk_{K}-metallicity/figures/metallicity-vs-activation.pdf\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48831101-1f9d-4871-aecb-2e941258e35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(activation_index):\n",
    "    return cnn_model.resnet.fc.weight[:, activation_index].cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e585a19d-9d43-4063-b116-a6a6e6fc22e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation  61 (N=23348): Pearson rho = +0.8513, Weight = +0.503\n",
      "Activation 256 (N=20605): Pearson rho = -0.7182, Weight = -0.593\n",
      "Activation  49 (N= 9414): Pearson rho = +0.5085, Weight = -0.103\n",
      "Activation 461 (N= 2784): Pearson rho = +0.2808, Weight = -0.176\n",
      "Activation 223 (N=   48): Pearson rho = -0.0580, Weight = +0.191\n",
      "Activation  87 (N=   40): Pearson rho = +0.0334, Weight = -0.026\n",
      "Activation  84 (N=    1): Pearson rho = -0.0108, Weight = -0.070\n",
      "Activation  44 (N=   10): Pearson rho = -0.0007, Weight = -0.010\n",
      "Activation 247 (N=    1): Pearson rho = +0.0038, Weight = -0.034\n",
      "Activation  94 (N=    2): Pearson rho = +0.0092, Weight = +0.101\n",
      "Activation 428 (N=    1): Pearson rho = +0.0078, Weight = +0.184\n"
     ]
    }
   ],
   "source": [
    "for k in feature_dict:\n",
    "    Pearson_rho = np.corrcoef(activations[:, k] / activations[:, k].max(), dls.valid.items.oh_p50)[0,1]\n",
    "    weight = get_weights(k)\n",
    "    print(f\"Activation {k:>3} (N={len(feature_dict[k]):>5}): Pearson rho = {Pearson_rho:+.4f}, Weight = {weight:+>6.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27181b1e-1d64-4268-a190-498c97e22778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.715713500976562"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bias\n",
    "cnn_model.resnet.fc.bias.cpu().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d657955",
   "metadata": {},
   "source": [
    "# Using top activations to predict metallicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "44bb778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_metallicity_topk(activations, model, top_n=100):\n",
    "\n",
    "    filtered_activations = activations.copy()\n",
    "\n",
    "    non_zero_counts = np.count_nonzero(filtered_activations, axis=0)\n",
    "    mask = non_zero_counts < top_n\n",
    "    filtered_activations[:, mask] = 0\n",
    "    \n",
    "    # Use the model to predict metallicity\n",
    "    return model.resnet.fc(torch.from_numpy(filtered_activations).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a25c5059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08645987215189249\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Z_preds = predict_metallicity_topk(activations, cnn_model.to(\"cpu\"), top_n=100).detach().numpy().flatten() \n",
    "Z_trues = dls.valid.items.oh_p50\n",
    "\n",
    "print(np.sqrt(((Z_trues - Z_preds)**2).mean()))\n",
    "\n",
    "plt.figure(figsize=(3.5, 3.5), dpi=300)\n",
    "plt.rcParams['font.weight'] = 700\n",
    "\n",
    "plt.scatter(Z_trues, Z_preds, s=1, rasterized=True)\n",
    "plt.xlabel(\"True metallicity\", fontsize=12, fontweight=\"bold\")\n",
    "plt.ylabel(\"Predicted metallicity\", fontsize=12, fontweight=\"bold\")\n",
    "plt.xlim(7.9, 9.3)\n",
    "plt.ylim(7.9, 9.3)\n",
    "plt.xticks(ticks=[8, 8.2, 8.4, 8.6, 8.8, 9, 9.2], labels=[8, 8.2, 8.4, 8.6, 8.8, 9, 9.2], fontsize=10)\n",
    "plt.yticks(ticks=[8, 8.2, 8.4, 8.6, 8.8, 9, 9.2], labels=[8, 8.2, 8.4, 8.6, 8.8, 9, 9.2], fontsize=10)\n",
    "plt.savefig(f\"{ROOT}/results/resnet18-topk_{K}-metallicity/figures/predictions-using-top100-activations_vs_true.pdf\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "08dac8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08655708714401142\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Z_preds = predict_metallicity_topk(activations, cnn_model.to(\"cpu\"), top_n=10000).detach().numpy().flatten() \n",
    "Z_trues = dls.valid.items.oh_p50\n",
    "\n",
    "print(np.sqrt(((Z_trues - Z_preds)**2).mean()))\n",
    "\n",
    "plt.figure(figsize=(3.5, 3.5), dpi=300)\n",
    "plt.rcParams['font.weight'] = 700\n",
    "\n",
    "plt.scatter(Z_trues, Z_preds, s=1, rasterized=True)\n",
    "plt.xlabel(\"True metallicity\", fontsize=12, fontweight=\"bold\")\n",
    "plt.ylabel(\"Predicted metallicity\", fontsize=12, fontweight=\"bold\")\n",
    "plt.xlim(7.9, 9.3)\n",
    "plt.ylim(7.9, 9.3)\n",
    "plt.xticks(ticks=[8, 8.2, 8.4, 8.6, 8.8, 9, 9.2], labels=[8, 8.2, 8.4, 8.6, 8.8, 9, 9.2], fontsize=10)\n",
    "plt.yticks(ticks=[8, 8.2, 8.4, 8.6, 8.8, 9, 9.2], labels=[8, 8.2, 8.4, 8.6, 8.8, 9, 9.2], fontsize=10)\n",
    "plt.savefig(f\"{ROOT}/results/resnet18-topk_{K}-metallicity/figures/predictions-using-top10000-activations_vs_true.pdf\")\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
