{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3e020f27-f9df-427b-ab22-b1d602920133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.basics import *\n",
    "from fastai.vision.all import *\n",
    "\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import cmasher as cmr\n",
    "\n",
    "ROOT = Path(\"..\").resolve()\n",
    "seed = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "16c071b7-7ad1-4bc1-bbf8-fc898f3e3b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.font_manager as fm\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "fm.fontManager.addfont(\"/Users/john/Library/Fonts/Nunito-Italic.otf\")\n",
    "fm.fontManager.addfont(\"/Users/john/Library/Fonts/Nunito-Regular.otf\")\n",
    "fm.fontManager.addfont(\"/Users/john/Library/Fonts/Nunito-Bold.otf\")\n",
    "fm.fontManager.addfont(\"/Users/john/Library/Fonts/Nunito-ExtraBold.otf\")\n",
    "\n",
    "plt.rcParams['font.family'] = 'Nunito'\n",
    "plt.rcParams['font.weight'] = \"bold\"\n",
    "plt.rcParams['mathtext.fontset'] = 'custom'\n",
    "plt.rcParams['mathtext.sf'] = 'Nunito'\n",
    "plt.rcParams['mathtext.rm'] = 'Nunito'\n",
    "plt.rcParams['mathtext.it'] = 'Nunito'\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=[\"#003f5c\",\"#2f4b7c\",\"#665191\",\"#a05195\",\"#d45087\",\"#f95d6a\",\"#ff7c43\",\"#ffa600\",])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a691254d-7d40-4cb1-bd9b-e046f58e6578",
   "metadata": {},
   "source": [
    "# Top-k resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdcc9afa-774f-4551-8738-6feeb82e4a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 4\n",
    "\n",
    "def RMSE(p, y): return torch.sqrt(MSELossFlat()(p, y))\n",
    "    \n",
    "class ResNetTopK(nn.Module):\n",
    "    \"\"\"Resnet18-like model with a single projection head at end, and a top-k \n",
    "    sparsity constraint in penultimate layer to encourage interpretability.\n",
    "    \"\"\"\n",
    "    def __init__(self, k=32, n_out=1000, pretrained=True, **kwargs):\n",
    "        super(ResNetTopK, self).__init__()\n",
    "        if pretrained:\n",
    "            self.resnet = resnet18(weights=ResNet18_Weights.DEFAULT, **kwargs)\n",
    "        else:\n",
    "            self.resnet = resnet18(weights=None, **kwargs)\n",
    "        self.k = k\n",
    "        # change n_out features\n",
    "        n_fc_in = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(n_fc_in, n_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # regular convnet up to final layer\n",
    "        features = nn.Sequential(*list(self.resnet.children())[:-1])(x)\n",
    "        features = torch.flatten(features, 1)\n",
    "        features = nn.functional.relu(features)\n",
    "        \n",
    "        # top-k constraint\n",
    "        topk_values, topk_indices = torch.topk(features, k=self.k, dim=1)\n",
    "        sparse_features = torch.zeros_like(features)\n",
    "        sparse_features.scatter_(1, topk_indices, topk_values)\n",
    "        \n",
    "        # final fully connected layer\n",
    "        x = self.resnet.fc(sparse_features)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ef1024b-4ee9-41c7-9a99-d69621c35726",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ROOT / 'data/galaxies.csv', dtype={'objID': str})\n",
    "\n",
    "df = df[\n",
    "    (df.nii_6584_flux / df.nii_6584_flux_err  > 3)\n",
    "    & (df.h_alpha_flux / df.h_alpha_flux_err > 3)\n",
    "    & (df.oiii_5007_flux / df.oiii_5007_flux_err  > 3)\n",
    "    & (df.h_beta_flux / df.h_beta_flux_err > 3)\n",
    "    & (df.nii_6584_flux < 1e5)\n",
    "    & (df.h_alpha_flux < 1e5)\n",
    "    & (df.oiii_5007_flux < 1e5)\n",
    "    & (df.h_beta_flux < 1e5)\n",
    "].copy()\n",
    "\n",
    "# df = df.sample(10000, random_state=256).copy()\n",
    "\n",
    "n_galaxies = len(df)\n",
    "\n",
    "# set a random state\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f3713f7-ea6c-47bf-8e72-403a7f82bf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new targets\n",
    "df[\"log_N2\"] = np.log10(df.nii_6584_flux)\n",
    "df[\"log_Ha\"] = np.log10(df.h_alpha_flux)\n",
    "df[\"log_O3\"] = np.log10(df.oiii_5007_flux)\n",
    "df[\"log_Hb\"] = np.log10(df.h_beta_flux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c949590-abe0-47d1-9ac7-955383dc5ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fastai \"data blocks\" determine how data can be fed into a model\n",
    "target = ['log_N2', 'log_Ha', 'log_O3', 'log_Hb']\n",
    "dblock = DataBlock(\n",
    "    blocks=(ImageBlock, RegressionBlock),\n",
    "    get_x=ColReader('objID', pref=f'{ROOT}/data/images-sdss/', suff='.jpg'),\n",
    "    get_y=ColReader(target),\n",
    "    splitter=RandomSplitter(0.2, seed=seed),\n",
    "    item_tfms=[Resize(160), CropPad(144)],\n",
    "    batch_tfms=aug_transforms(do_flip=True, flip_vert=True, max_rotate=0, max_zoom=1.0, max_warp=0, p_lighting=0) + [Normalize()]\n",
    ")\n",
    "\n",
    "# \"data loaders\" actually load the data \n",
    "dls = ImageDataLoaders.from_dblock(dblock, df, bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5486d382-30d6-49c3-9009-975438bb9fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = ResNetTopK(k=K, n_out=len(target), pretrained=True).to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85a958b0-cd1d-4a2f-8bc8-9d79841dac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(\n",
    "    dls,\n",
    "    cnn_model,\n",
    "    loss_func=RMSE,\n",
    "    opt_func=ranger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bbb25f2-6e38-48c4-9729-f2c8cf2e2bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.329444</td>\n",
       "      <td>0.523534</td>\n",
       "      <td>26:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.290950</td>\n",
       "      <td>0.475089</td>\n",
       "      <td>25:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.276437</td>\n",
       "      <td>0.493881</td>\n",
       "      <td>25:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.270659</td>\n",
       "      <td>0.426233</td>\n",
       "      <td>24:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.274248</td>\n",
       "      <td>0.277130</td>\n",
       "      <td>24:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.266218</td>\n",
       "      <td>0.262335</td>\n",
       "      <td>24:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.255639</td>\n",
       "      <td>0.251537</td>\n",
       "      <td>24:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.256020</td>\n",
       "      <td>0.268484</td>\n",
       "      <td>24:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.250086</td>\n",
       "      <td>0.248310</td>\n",
       "      <td>25:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.241837</td>\n",
       "      <td>0.241771</td>\n",
       "      <td>25:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4ab6b80-899d-4374-a9f9-50d63b821cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hz/8kslz26x4w72kd6r6lm3zc480000gn/T/ipykernel_22089/2749903509.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cnn_model = torch.load(model_path)\n"
     ]
    }
   ],
   "source": [
    "model_path = f\"{ROOT}/model/resnet18-topk_{K}-bpt_lines.pth\"\n",
    "torch.save(learn.model, model_path)\n",
    "\n",
    "cnn_model = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379c94e0-6f15-4c48-b6f0-ccce8e4a8546",
   "metadata": {},
   "source": [
    "# View activated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fdb88dd-ed0c-4755-81d1-f69b631899c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_sparse_activations(loader, model):\n",
    "    activations = []\n",
    "    with torch.no_grad():\n",
    "        layers = nn.Sequential(*list(model.resnet.children())[:-1], nn.Flatten())\n",
    "        \n",
    "        for xb, _ in tqdm(loader):    \n",
    "            activations.append(layers(xb))\n",
    "    return torch.concat(activations, 0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a0bdef0-b58d-46ef-af83-ef446d0b464e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 782/782 [02:04<00:00,  6.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50041, 512)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activs = get_all_sparse_activations(dls.valid, cnn_model)\n",
    "activs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "609732da-cec5-4c5a-96d0-9df284852bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "activs_path = f\"{ROOT}/results/resnet18-topk_{K}-bpt_lines/activations.npy\"\n",
    "np.save(activs_path, activs)\n",
    "\n",
    "activations = np.load(activs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d991a71c-e9e9-4dd7-bb04-fd55be7d3b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(activations.max(0) > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cc94148-1f37-4048-96f3-14e6aa54ad31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make a dictionary for every non-zero activated feature, where the\n",
    "# key is the latent activation index, and the value is a list of tuples\n",
    "# of (image index, activation strength)\n",
    "feature_dict = defaultdict(list)\n",
    "\n",
    "# Process each image's activations\n",
    "for img_idx, img_activations in enumerate(activations):\n",
    "    # Find non-zero activations\n",
    "    non_zero = np.nonzero(img_activations)[0]\n",
    "\n",
    "    # Add to dictionary\n",
    "    for feature_idx in non_zero:\n",
    "        activation_strength = img_activations[feature_idx]\n",
    "        feature_dict[int(feature_idx)].append((int(img_idx), float(activation_strength)))\n",
    "\n",
    "# Sort each list by activation strength in descending order\n",
    "for feature_idx in feature_dict:\n",
    "    feature_dict[feature_idx].sort(key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63fe939f-8a5a-4ea2-b336-b1dd2c9504b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(17, 31488), (138, 43517), (157, 47936), (322, 31500), (337, 25081), (399, 25497), (236, 29180), (242, 19432), (8, 5), (111, 2), (336, 60), (365, 2), (478, 3), (58, 1), (410, 1), (194, 1), (357, 1), (458, 4), (473, 4), (508, 1), (44, 5), (133, 1), (59, 2), (292, 1)]\n"
     ]
    }
   ],
   "source": [
    "print([(k, len(feature_dict[k])) for k in feature_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d1e5267-b3e9-4041-95bf-2bc7bf17382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_idx_to_objid = lambda idx: dls.valid.items.iloc[idx].objID\n",
    "\n",
    "def plot_max_activating_galaxies(feature_dict, activation_index, top_n=5):\n",
    "    galaxy_indices_and_activations = feature_dict[activation_index]\n",
    "\n",
    "    top_n = min(top_n, len(galaxy_indices_and_activations))\n",
    "\n",
    "    fig, axes = plt.subplots(1, top_n, figsize=(top_n * 1.5, 2), dpi=100, squeeze=0)\n",
    "    axes = axes.reshape(-1)\n",
    "    for ax, [galaxy_index, feature_activation] in zip(axes, galaxy_indices_and_activations):\n",
    "        image = Image.open(f\"{ROOT}/data/images-sdss/{valid_idx_to_objid(galaxy_index)}.jpg\")\n",
    "        ax.imshow(image, origin='lower')\n",
    "        ax.set_title(f\"{feature_activation:.4f}\", fontsize=10)\n",
    "        ax.axis(\"off\")\n",
    "    fig.suptitle(f\"Activation {activation_index} ({len(galaxy_indices_and_activations)} galaxies)\", fontsize=12)\n",
    "    fig.subplots_adjust(left=0, right=1, top=0.8, wspace=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "be421e25-d089-44b0-b976-2efc761abcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00, 10.82it/s]\n"
     ]
    }
   ],
   "source": [
    "for k in tqdm(feature_dict):\n",
    "    plot_max_activating_galaxies(feature_dict, k, top_n=10)\n",
    "    plt.savefig(f\"{ROOT}/results/resnet18-topk_{K}-bpt_lines/figures/{k}-examples.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168eccee-f810-4a2b-99cc-367427b57817",
   "metadata": {},
   "source": [
    "# Show on BPT diagram normalized activation \n",
    "\n",
    "Only use common activations (i.e. ones that have non-zero values for 100+ cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d896b810-7e95-490e-93fd-4fb9446651d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.weight'] = 700\n",
    "\n",
    "for k in feature_dict:\n",
    "    plt.figure(figsize=(4.8, 4), dpi=300)\n",
    "    \n",
    "    n2_ha = dls.valid.items.log_N2 - dls.valid.items.log_Ha\n",
    "    o3_hb = dls.valid.items.log_O3 - dls.valid.items.log_Hb\n",
    "\n",
    "    act_strength = activations[:, k] / activations[:, k].max()\n",
    "\n",
    "    n2_ha = n2_ha.iloc[np.argsort(act_strength)]\n",
    "    o3_hb = o3_hb.iloc[np.argsort(act_strength)]\n",
    "    act_strength = act_strength[np.argsort(act_strength)]\n",
    "    \n",
    "    plt.scatter(\n",
    "        n2_ha,\n",
    "        o3_hb,\n",
    "        c=act_strength, \n",
    "        edgecolors=\"none\",\n",
    "        cmap=cmr.ember,\n",
    "        s=1,\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "    )\n",
    "    cb = plt.colorbar()\n",
    "    cb.set_label(label=\"Activation Strength\", fontsize=12, fontfamily=\"Nunito\", fontweight=\"bold\")\n",
    "\n",
    "    plt.title(f\"Activation {k:>3} ($N$ = {len(feature_dict[k])})\", fontsize=12, fontfamily=\"Nunito\", fontweight=\"bold\")\n",
    "    \n",
    "    plt.xlabel(\"log([NII]/H$\\\\alpha$)\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.ylabel(\"log([OIII]/H$\\\\beta$)\", fontsize=12, fontweight=\"bold\")\n",
    "    # plt.legend(markerscale=10, loc=\"center right\", framealpha=0, markerfirst=False, borderpad=0.05, handletextpad=0.05, title_fontsize=14)\n",
    "    plt.grid(alpha=0.15)\n",
    "    plt.xlim(-1.55, 0.55)\n",
    "    plt.ylim(-1.05, 1.3)\n",
    "    plt.savefig(f\"{ROOT}/results/resnet18-topk_{K}-bpt_lines/figures/{k}-bpt_scatter.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27181b1e-1d64-4268-a190-498c97e22778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
